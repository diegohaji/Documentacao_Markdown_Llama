{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "# Insira seu token de acesso pessoal\n",
    "login(\"Your_HuggingFace_API_Key\",add_to_git_credential=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    torch_dtype=torch.float32,\n",
    "    device = 'cuda',\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codigo = \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"Você é um bot que explica códigos em python\"},\n",
    "    {\"role\": \"user\", \"content\": f\"Me diga o que o seguinte código faz: \\n{codigo}\"},\n",
    "]\n",
    "outputs = pipe(\n",
    "    messages,\n",
    "    max_new_tokens=256,\n",
    ")\n",
    "\n",
    "# Melhorando a legibilidade do print\n",
    "response = outputs[0][\"generated_text\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"Você é um bot que recebe explicacões de códigos em python e gera documentações em markdown a partir desses comentários.\"},\n",
    "    {\"role\": \"user\", \"content\": f\"{response[2]}\"},\n",
    "]\n",
    "outputs = pipe(\n",
    "    messages,\n",
    "    max_new_tokens=1024,\n",
    ")\n",
    "\n",
    "# Melhorando a legibilidade do print\n",
    "response_doc = outputs[0][\"generated_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterar sobre a lista e formatar os itens\n",
    "response_list = response_doc  # Substitua por sua variável exata\n",
    "formatted_response = \"\"\n",
    "\n",
    "for item in response_list:\n",
    "    # Adicionar cada elemento da lista como um bloco formatado\n",
    "    if isinstance(item, dict):\n",
    "        # Formatando dicionário como JSON legível\n",
    "        import json\n",
    "        formatted_response += f\"```json\\n{json.dumps(item, indent=2, ensure_ascii=False)}\\n```\\n\\n\"\n",
    "    else:\n",
    "        # Adicionar elementos simples diretamente\n",
    "        formatted_response += f\"{str(item)}\\n\\n\"\n",
    "\n",
    "# Criar um Markdown-friendly string\n",
    "markdown_response = f\"\"\"\n",
    "# Resposta do Modelo\n",
    "\n",
    "{formatted_response}\n",
    "\"\"\"\n",
    "\n",
    "print(markdown_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraindo a documentação gerada pelo assistente\n",
    "documentation_content = \"\"\n",
    "\n",
    "for item in response_doc:\n",
    "    if item[\"role\"] == \"assistant\":\n",
    "        documentation_content += item[\"content\"]\n",
    "\n",
    "# Salvando ou adicionando ao arquivo Markdown\n",
    "output_file_path = \"documentacao_codigo_test.md\"\n",
    "\n",
    "# Abrir o arquivo em modo de adição (\"a\") para não sobrescrever o conteúdo existente\n",
    "with open(output_file_path, \"a\", encoding=\"utf-8\") as file:\n",
    "    # Adicionar separadores para distinguir diferentes seções, se necessário\n",
    "    file.write(\"\\n\\n---\\n\\n\")  # Adiciona uma linha horizontal (Markdown: \"---\")\n",
    "    file.write(documentation_content)\n",
    "\n",
    "print(f\"Conteúdo adicionado ao arquivo: {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "393a2753ccc14ffb9e709ea22505e392",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    torch_dtype=torch.float32,\n",
    "    device = 'cuda',\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45 células de código encontradas para processar.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando células de código:   0%|          | 0/45 [00:00<?, ?célula/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processando células de código:   2%|▏         | 1/45 [06:00<4:24:18, 360.42s/célula]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processando células de código:   4%|▍         | 2/45 [12:08<4:21:26, 364.79s/célula]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processando células de código:   7%|▋         | 3/45 [22:17<5:33:24, 476.29s/célula]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processando células de código:   9%|▉         | 4/45 [30:51<5:35:39, 491.20s/célula]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processando células de código:  11%|█         | 5/45 [37:15<5:01:46, 452.65s/célula]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processando células de código:  13%|█▎        | 6/45 [43:35<4:38:05, 427.84s/célula]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processando células de código:  16%|█▌        | 7/45 [1:00:19<6:30:24, 616.43s/célula]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processando células de código:  18%|█▊        | 8/45 [1:09:14<6:04:05, 590.42s/célula]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processando células de código:  20%|██        | 9/45 [1:16:55<5:29:53, 549.82s/célula]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processando células de código:  22%|██▏       | 10/45 [1:25:00<5:09:03, 529.82s/célula]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processando células de código:  24%|██▍       | 11/45 [1:38:28<5:48:29, 614.98s/célula]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processando células de código:  27%|██▋       | 12/45 [1:47:05<5:21:53, 585.27s/célula]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processando células de código:  29%|██▉       | 13/45 [1:58:02<5:23:41, 606.92s/célula]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processando células de código:  31%|███       | 14/45 [2:12:01<5:49:50, 677.11s/célula]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processando células de código:  33%|███▎      | 15/45 [2:23:23<5:39:19, 678.65s/célula]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processando células de código:  36%|███▌      | 16/45 [2:31:50<5:03:00, 626.91s/célula]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processando células de código:  38%|███▊      | 17/45 [2:41:22<4:44:47, 610.27s/célula]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processando células de código:  40%|████      | 18/45 [2:54:44<5:00:33, 667.92s/célula]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processando células de código:  42%|████▏     | 19/45 [3:08:40<5:11:21, 718.54s/célula]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processando células de código:  44%|████▍     | 20/45 [3:17:13<4:33:39, 656.78s/célula]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processando células de código:  47%|████▋     | 21/45 [3:37:13<5:27:52, 819.68s/célula]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processando células de código:  49%|████▉     | 22/45 [3:44:51<4:32:35, 711.09s/célula]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processando células de código:  51%|█████     | 23/45 [3:57:36<4:26:44, 727.48s/célula]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processando células de código:  53%|█████▎    | 24/45 [4:05:04<3:45:13, 643.49s/célula]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processando células de código:  56%|█████▌    | 25/45 [4:19:45<3:58:19, 714.96s/célula]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processando células de código:  58%|█████▊    | 26/45 [4:26:42<3:18:03, 625.45s/célula]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processando células de código:  60%|██████    | 27/45 [4:42:10<3:34:52, 716.25s/célula]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processando células de código:  62%|██████▏   | 28/45 [4:56:51<3:36:56, 765.67s/célula]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processando células de código:  64%|██████▍   | 29/45 [5:04:23<2:59:05, 671.58s/célula]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processando células de código:  67%|██████▋   | 30/45 [5:25:04<3:30:36, 842.44s/célula]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processando células de código:  69%|██████▉   | 31/45 [5:31:07<2:42:57, 698.37s/célula]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processando células de código:  71%|███████   | 32/45 [5:37:48<2:11:59, 609.22s/célula]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processando células de código:  73%|███████▎  | 33/45 [5:46:40<1:57:13, 586.12s/célula]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processando células de código:  76%|███████▌  | 34/45 [5:52:39<1:34:59, 518.14s/célula]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processando células de código:  78%|███████▊  | 35/45 [5:59:00<1:19:27, 476.72s/célula]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processando células de código:  80%|████████  | 36/45 [6:05:41<1:08:06, 454.04s/célula]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processando células de código:  82%|████████▏ | 37/45 [6:15:01<1:04:46, 485.84s/célula]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processando células de código:  84%|████████▍ | 38/45 [6:21:44<53:46, 460.94s/célula]  Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processando células de código:  87%|████████▋ | 39/45 [6:27:56<43:26, 434.34s/célula]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processando células de código:  89%|████████▉ | 40/45 [6:37:24<39:32, 474.45s/célula]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processando células de código:  91%|█████████ | 41/45 [6:44:08<30:13, 453.39s/célula]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processando células de código:  93%|█████████▎| 42/45 [6:50:48<21:52, 437.34s/célula]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processando células de código:  96%|█████████▌| 43/45 [6:57:16<14:05, 422.51s/célula]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processando células de código:  98%|█████████▊| 44/45 [7:04:22<07:03, 423.67s/célula]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processando células de código: 100%|██████████| 45/45 [7:11:48<00:00, 575.75s/célula]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "write() argument must be str, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 60\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(code_cells)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m células de código encontradas para processar.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     59\u001b[0m markdown_responses \u001b[38;5;241m=\u001b[39m process_code_with_model(code_cells, pipe)\n\u001b[1;32m---> 60\u001b[0m \u001b[43msave_to_markdown_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmarkdown_responses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDocumentação salva em: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_file_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[3], line 46\u001b[0m, in \u001b[0;36msave_to_markdown_file\u001b[1;34m(markdown_responses, output_file_path)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m markdown_response \u001b[38;5;129;01min\u001b[39;00m markdown_responses:\n\u001b[0;32m     45\u001b[0m     file\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m---\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Separador entre seções\u001b[39;00m\n\u001b[1;32m---> 46\u001b[0m     \u001b[43mfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmarkdown_response\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: write() argument must be str, not list"
     ]
    }
   ],
   "source": [
    "import nbformat\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "# Função para filtrar células de código relevantes\n",
    "def extract_code_cells(notebook_path):\n",
    "    with open(notebook_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        nb = nbformat.read(f, as_version=4)\n",
    "    \n",
    "    code_cells = []\n",
    "    for cell in nb[\"cells\"]:\n",
    "        if cell[\"cell_type\"] == \"code\":\n",
    "            # Ignorar células vazias ou com apenas comentários\n",
    "            code = cell[\"source\"].strip()\n",
    "            if code and not all(line.strip().startswith(\"#\") for line in code.splitlines()):\n",
    "                code_cells.append(code)\n",
    "    return code_cells\n",
    "\n",
    "# Função para processar cada célula de código com o modelo\n",
    "def process_code_with_model(code_cells, pipe):\n",
    "    markdown_responses = []\n",
    "    for code in tqdm(code_cells, desc=\"Processando células de código\", unit=\"célula\"):\n",
    "        # Alimentar o código para o modelo\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"Você é um bot que explica códigos em python\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Me diga o que o seguinte código faz: \\n{code}\"},\n",
    "        ]\n",
    "        outputs = pipe(messages, max_new_tokens=256)\n",
    "        response = outputs[0][\"generated_text\"]\n",
    "\n",
    "        # Gerar explicações em Markdown\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"Você é um bot que recebe explicacões de códigos em python e gera documentações em markdown a partir desses comentários.\"},\n",
    "            {\"role\": \"user\", \"content\": response},\n",
    "        ]\n",
    "        outputs = pipe(messages, max_new_tokens=1024)\n",
    "        markdown_response = outputs[0][\"generated_text\"]\n",
    "        markdown_responses.append(markdown_response)\n",
    "    return markdown_responses\n",
    "\n",
    "# Função para salvar em um arquivo Markdown\n",
    "def save_to_markdown_file(markdown_responses, output_file_path):\n",
    "    with open(output_file_path, \"a\", encoding=\"utf-8\") as file:\n",
    "        for markdown_response in markdown_responses:\n",
    "            # Extrair apenas o conteúdo do \"role\": \"assistant\"\n",
    "            if isinstance(markdown_response, list):\n",
    "                assistant_responses = [\n",
    "                    msg.get(\"content\", \"\") for msg in markdown_response if msg.get(\"role\") == \"assistant\"\n",
    "                ]\n",
    "                markdown_response = \"\\n\".join(assistant_responses)\n",
    "            elif isinstance(markdown_response, dict):\n",
    "                markdown_response = markdown_response.get(\"content\", \"\") if markdown_response.get(\"role\") == \"assistant\" else \"\"\n",
    "            \n",
    "            # Adiciona separadores e salva no arquivo\n",
    "            file.write(\"\\n\\n---\\n\\n\")  # Separador entre seções\n",
    "            file.write(markdown_response)\n",
    "\n",
    "# Caminho do notebook e arquivo de saída\n",
    "notebook_path = \"channel_segmentation_presal_clean_Full_semi_supervised_CI.ipynb\"  # Substitua pelo caminho do seu notebook\n",
    "output_file_path = \"documentacao_codigo_final.md\"\n",
    "\n",
    "# Extração e processamento\n",
    "code_cells = extract_code_cells(notebook_path)\n",
    "\n",
    "if not code_cells:\n",
    "    print(\"Nenhuma célula de código relevante encontrada.\")\n",
    "else:\n",
    "    print(f\"{len(code_cells)} células de código encontradas para processar.\")\n",
    "    markdown_responses = process_code_with_model(code_cells, pipe)\n",
    "    save_to_markdown_file(markdown_responses, output_file_path)\n",
    "    print(f\"Documentação salva em: {output_file_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
